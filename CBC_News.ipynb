{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBC News (Web Scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from pandasql import sqldf\n",
    "import time\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Function for Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execSQL(conn,query):\n",
    "  conn.execute(query) # execute an SQL query\n",
    "  conn.commit() # \"commit\" that query in order to make its action permanent\n",
    "\n",
    "pysqldf = lambda q: sqldf(q, globals())  # Querying Pandas Dataframes using SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove earlier copy of cbcnews.db\n"
     ]
    }
   ],
   "source": [
    "# Remove the database if it is already here\n",
    "try:\n",
    "  os.remove(\"cbcnews.db\")\n",
    "  print(\"remove earlier copy of cbcnews.db\")\n",
    "except:\n",
    "  print(\"not already here\")  \n",
    "\n",
    "# create new one\n",
    "conn = sqlite3.connect(\"cbcnews.db\")\n",
    "\n",
    "# enable foreign keys\n",
    "execSQL(conn,\"PRAGMA foreign_keys=ON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Tables in Database\n",
    "\n",
    "- Table 1\n",
    "    - store the data id\n",
    "    - conventient for checking the duplicate data id\n",
    "- Table 2\n",
    "    - set foreign key, linkage with the Table 1\n",
    "    - update data fields \n",
    "        1. data id\n",
    "        2. title\n",
    "        3. description\n",
    "        4. link\n",
    "        5. timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1: id_table\n",
    "createCMD='''\n",
    "CREATE TABLE id_table( \n",
    "  DataID TEXT PRIMARY KEY\n",
    ")\n",
    "'''\n",
    "\n",
    "execSQL(conn,createCMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 2: content_table\n",
    "createCMD='''\n",
    "CREATE TABLE content_table(\n",
    "  DataID TEXT PRIMARY KEY,\n",
    "  Title  TEXT,\n",
    "  Description  TEXT,\n",
    "  Link  TEXT,\n",
    "  TimeStamp  TEXT,\n",
    "  FOREIGN KEY(DataID) REFERENCES id_table(DataID)\n",
    ")\n",
    "'''\n",
    "\n",
    "execSQL(conn,createCMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_data_id():\n",
    "    # grab the database\n",
    "    df_content = pd.read_sql_query(\"SELECT * FROM id_table\", conn)\n",
    "    exist_id_list = df_content['DataID'].to_list()\n",
    "    return exist_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping(link):\n",
    "    resp = requests.get(link)\n",
    "    # Exceptional case\n",
    "    if resp.status_code != 200:\n",
    "        print(f'Invalid Status Code: {resp.status_code}')\n",
    "        return False\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')\n",
    "    # Get primary and secondary stories\n",
    "    primary_stories = soup.find('div', {'class': 'primaryTopStories'})\n",
    "    secondary_stories = soup.find('div', {'class': 'secondaryTopStories'})\n",
    "    \n",
    "    # Split the stories into each cell of ResultSet (just like list)\n",
    "    primary_story_items = primary_stories.findAll('a', {'data-test': 'type-story'})\n",
    "    secondary_story_items = secondary_stories.findAll('a', {'data-test': 'type-story'})\n",
    "    \n",
    "    # Update exist id list\n",
    "    exist_id_list = grad_data_id()\n",
    "    \n",
    "    # Grab data fields of each story\n",
    "    # Alternate method: write a function to replace two for-loops\n",
    "    \n",
    "    # Primary Stories\n",
    "    for item_num in range(len(primary_story_items)):\n",
    "        item_id = primary_story_items[item_num].attrs['data-contentid']\n",
    "        item_link = primary_story_items[item_num].attrs['href']\n",
    "        item_title = primary_story_items[item_num].find('h3', {'class': 'headline'}).text\n",
    "        item_description = primary_story_items[item_num].find('div', {'class': 'description'}).text\n",
    "        item_timestamp = primary_story_items[item_num].find('time', {'class': 'timeStamp'}).attrs['datetime']\n",
    "        # check data id with the first table(id_table) in database\n",
    "        if not (item_id in exist_id_list):\n",
    "            # after checking, there is a new story\n",
    "            new_item = pd.DataFrame({'DataID': item_id, 'Title': item_title, \n",
    "                                    'Description': item_description, 'Link': item_link, \n",
    "                                    'TimeStamp': item_timestamp}, index=[0])\n",
    "            new_id = pd.DataFrame({'DataID': item_id}, index=[0])\n",
    "            # update to database\n",
    "            new_id.to_sql('id_table', conn, if_exists='append', index=False)\n",
    "            new_item.to_sql('content_table', conn, if_exists='append', index=False)\n",
    "            print(f'{dt.strptime(item_timestamp, \"%Y-%m-%dT%H:%M:%S.%fZ\").strftime(\"%Y-%m-%d %H:%M:%S\")}\\n{item_title}\\n')\n",
    "            # tg_bot_message(f'{dt.strptime(item_timestamp, \"%Y-%m-%dT%H:%M:%S.%fZ\").strftime(\"%Y-%m-%d %H:%M:%S\")}\\n{item_title}')\n",
    "\n",
    "    # Secondary Stories\n",
    "    for item_num in range(len(secondary_story_items)):\n",
    "        item_id = secondary_story_items[item_num].attrs['data-contentid']\n",
    "        item_link = secondary_story_items[item_num].attrs['href']\n",
    "        item_title = secondary_story_items[item_num].find('h3', {'class': 'headline'}).text\n",
    "        item_timestamp = secondary_story_items[item_num].find('time', {'class': 'timeStamp'}).attrs['datetime']\n",
    "        item_description = None\n",
    "        # check data id with the first table(id_table) in database\n",
    "        if not (item_id in exist_id_list):\n",
    "            # after checking, there is a new story\n",
    "            new_item = pd.DataFrame({'DataID': item_id, 'Title': item_title, \n",
    "                                    'Description': item_description, 'Link': item_link, \n",
    "                                    'TimeStamp': item_timestamp}, index=[0])\n",
    "            new_id = pd.DataFrame({'DataID': item_id}, index=[0])\n",
    "            # update to database\n",
    "            new_id.to_sql('id_table', conn, if_exists='append', index=False)\n",
    "            new_item.to_sql('content_table', conn, if_exists='append', index=False)\n",
    "            print(f'{dt.strptime(item_timestamp, \"%Y-%m-%dT%H:%M:%S.%fZ\").strftime(\"%Y-%m-%d %H:%M:%S\")}\\n{item_title}\\n')\n",
    "            # tg_bot_message(f'{dt.strptime(item_timestamp, \"%Y-%m-%dT%H:%M:%S.%fZ\").strftime(\"%Y-%m-%d %H:%M:%S\")}\\n{item_title}')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tg_bot_message(message):\n",
    "    chat_id = None\n",
    "    token = ''\n",
    "    payload = {'chat_id': chat_id, 'text': message}\n",
    "    requests.get(f'https://api.telegram.org/bot{token}/sendMessage', data=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-27 12:00:00\n",
      "Alberta's big budget question: What to do with the torrent of cash flooding provincial coffers\n",
      "\n",
      "2023-02-27 17:41:22\n",
      "Alberta, Ottawa sign health-care funding deal worth $24B over 10 years\n",
      "\n",
      "2023-02-27 15:20:08\n",
      "Canmore residents long for more permanent neighbours as 'weekenders' snap up homes\n",
      "\n",
      "2023-02-27 13:31:15\n",
      "Battleground Calgary: Alberta NDP move election campaign HQ to city's core\n",
      "\n",
      "2023-02-26 17:52:27\n",
      "From well cleanups to Sovereignty Act, Danielle Smith's big ideas keep deflating\n",
      "\n",
      "2023-02-27 13:00:00\n",
      "Edmonton has seen more opioid-related EMS calls than Calgary for past 2 years\n",
      "\n",
      "2023-02-27 12:00:00\n",
      "Want to know how COVID-19 subvariants are behaving in Alberta? Now it's a bit easier\n",
      "\n",
      "2023-02-27 09:00:00\n",
      "Lock the doors. Get straight home. I live in fear because of hate crimes committed against others\n",
      "\n",
      "2023-02-27 20:25:53\n",
      "Statistics Canada study on Black-owned businesses suggests systemic challenges hold them back\n",
      "\n",
      "2023-02-26 15:00:00\n",
      "How this facility in central Alberta is giving new life to oil waste\n",
      "\n",
      "2023-02-26 20:54:00\n",
      "Could the 'virtual power plant' model convince more Albertans to switch to solar?\n",
      "\n",
      "2023-02-27 13:08:43\n",
      "Gunfire exchange leads to charges for Canmore, Alta., man: RCMP\n",
      "\n",
      "2023-02-27 16:11:47\n",
      "Interest rate hikes have yet to bring down food prices. Here are the tools governments could try\n",
      "\n",
      "2023-02-26 19:32:04\n",
      "This Calgary organization is helping newcomer youth find community and a sense of belonging\n",
      "\n",
      "2023-02-27 20:44:44\n",
      "No more clumpy lipgloss: How TikTok's 'deinfluencing' trend became a marketing tactic\n",
      "\n",
      "2023-02-26 14:00:00\n",
      "Northern Alberta wellness camp shows potential of Indigenous tourism\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStop Scraping\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# check news every 5 mins\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Target Link\n",
    "url = 'https://www.cbc.ca/news/canada/calgary'\n",
    "flag = True\n",
    "while flag:\n",
    "    flag = scraping(url)\n",
    "    if not (flag):\n",
    "        print('Stop Scraping')\n",
    "        break\n",
    "    time.sleep(300) # check news every 5 mins"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
